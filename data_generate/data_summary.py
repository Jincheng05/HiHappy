#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import glob
import json
import time
import requests
import threading
from datetime import datetime
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

DATA_DIR = "/mnt/nvme1n1/wjc/dataset_no_pre/dataset"
OUTPUT_PATH = "/mnt/nvme1n1/wjc/dataset_no_pre/perprepared/train_concurrency_en_cot.jsonl"

VLLM_URL = "http://localhost:6006/v1/chat/completions"
VLLM_MODEL = "/mnt/nvme1n1/wjc/Model/Qwen2.5-7B-Instruct"

MAX_NEW_TOKENS = 4048
TEMPERATURE = 0.3
TOP_P = 1.0
RETRY_TIMES = 3
TIMEOUT = 30
PREVIEW_LENGTH = 3000

MAX_CONCURRENCY = 15
WRITE_LOCK = threading.Lock()
def print_simple(msg):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}")

def build_dialog_text(messages):
    parts = []
    noise_keywords = ["Âíå‰Ω†ËÅäÂ§©", "ÂêÉÈ•≠", "Âú®Âêó", "ÊµãËØï", "Êó†ÊïàÂÜÖÂÆπ", "Âç†‰ΩçÁ¨¶"]
    for m in messages:
        role = m.get("role", "Êú™Áü•ËßíËâ≤")
        content = (m.get("content") or "").strip()
        
        if (not content 
            or len(content) < 3 
            or role == "system" 
            or any(keyword in content for keyword in noise_keywords)):
            continue
        
        parts.append(f"„ÄêÂéüÂßãËßíËâ≤Ôºö{role}„Äë{content}")
    
    return "\n".join(parts)

def clean_extraction_result(extraction: str) -> Optional[str]:
    if not extraction:
        return None
    
    json_start = extraction.find("{")
    json_end = extraction.rfind("}")
    if json_start != -1:
        if json_end == -1:
            extraction = extraction[json_start:] + "}"
        else:
            extraction = extraction[json_start:json_end+1].strip()
    
    return extraction

def call_vllm(url: str, model: str, messages: List[Dict], max_tokens: int = 1024) -> Optional[str]:
    stop_words = ["}"]
    
    body = {
        "model": model,
        "messages": messages,
        "temperature": TEMPERATURE,
        "top_p": TOP_P,
        "max_tokens": max_tokens,
        "stream": False,
        "presence_penalty": 1.0,
        "frequency_penalty": 1.0,
    }

    for retry in range(RETRY_TIMES):
        try:
            resp = requests.post(url, json=body, timeout=TIMEOUT)
            if resp.status_code == 200:
                return resp.json()["choices"][0]["message"]["content"].strip()
            else:
                print_simple(f"‚ö†Ô∏è VLLM request failed: status {resp.status_code}, retry {retry+1}")
        except Exception as e:
            print_simple(f"‚ö†Ô∏è VLLM call error: {str(e)[:50]}, retry {retry+1}")
            time.sleep(2 * (retry + 1))
    
    return None

def call_chatmodeldp(dialog_text: str) -> Optional[str]:
    system_prompt = (
        "‰Ω†ÊòØ‰∏ì‰∏öÁöÑÂøÉÁêÜÂí®ËØ¢ÂØπËØù‰ø°ÊÅØÊäΩÂèñ‰∏ìÂÆ∂ÔºåÈúÄ‰∏•Ê†ºÈÅµÂÆà‰ª•‰∏ãÊåá‰ª§ÂÆåÊàê‰ø°ÊÅØÊèêÂèñÔºå‰ªª‰ΩïËøùËßÑËæìÂá∫ÂùáËßÜ‰∏∫Êó†ÊïàÔºö\n"
        "„ÄêÊ†ºÂºèÈìÅÂæãÔºàÂøÖÈ°ª100%ÈÅµÂÆàÔºâ„Äë\n"
        "1. ËæìÂá∫ÂÜÖÂÆπ‰ªÖÂåÖÂê´ÂÆåÊï¥ÁöÑJSONÂ≠óÁ¨¶‰∏≤ÔºåÊó†‰ªª‰ΩïÂâçÁΩÆ„ÄÅÂêéÁΩÆÊñáÂ≠óÔºàÂ¶Ç‚ÄúÂ•ΩÁöÑ‚Äù‚Äú‰ª•‰∏ãÊòØÁªìÊûú‚ÄùÁ≠âÔºâÔºõ\n"
        "2. JSONÂøÖÈ°ª‰ª•`{`ÂºÄÂ§¥„ÄÅ`}`ÁªìÂ∞æÔºåÁªìÊûÑÂÆåÊï¥Èó≠ÂêàÔºåÁº∫Â§±ÁªìÂ∞æ`}`Áõ¥Êé•Âà§ÂÆö‰∏∫ËæìÂá∫ÈîôËØØÔºõ\n"
        "3. JSONÂÜÖÊØè‰∏™Â≠óÊÆµÁöÑÂÄºÂùá‰∏∫‰∏≠ÊñáÊñáÊú¨ÔºåÊó†ËØ≠Ê≥ïÈîôËØØ„ÄÅÊó†ÁúÅÁï•Âè∑ÔºåÊ†áÁÇπ‰ΩøÁî®ËßÑËåÉ„ÄÇ\n"
        "„ÄêÂÜÖÂÆπÂàõ‰ΩúÊéàÊùÉÔºàÂÖÅËÆ∏Ê∂¶Ëâ≤+Ê∑ªÂä†Áõ∏ÂÖ≥ÂÜÖÂÆπÔºâ„Äë\n"
        "1. Ê†∏ÂøÉÂéüÂàôÔºöÂü∫‰∫éÂØπËØù‰∏≠Â∑≤ÊúâÁöÑÁúüÂÆû‰ø°ÊÅØÔºåÂèØÂÖÖÂàÜÊ∂¶Ëâ≤ËØ≠Ë®ÄÔºà‰ΩøË°®Ëø∞Êõ¥ÊµÅÁïÖ,‰ΩÜÊòØÈúÄË¶ÅÂè£ËØ≠ÂåñÔºâÔºåÂπ∂ÂêàÁêÜÊ∑ªÂä†**Á¨¶ÂêàÈÄªËæëÁöÑÁõ∏ÂÖ≥ÂÜÖÂÆπ**ÔºàÁ¶ÅÊ≠¢ÁºñÈÄ†‰∏éÂØπËØùÊó†ÂÖ≥ÁöÑÊ†∏ÂøÉ‰∫ãÂÆûÔºåÂ¶ÇÊú™ÊèêÂèäÁöÑÊàêÁª©„ÄÅ‰∫ã‰ª∂„ÄÅ‰∫∫Áâ©Á≠âÔºâÔºõ\n"
        "2. ÂèØÊ∂¶Ëâ≤/Ê∑ªÂä†ÁöÑÂÜÖÂÆπÁ±ªÂûãÔºö\n"
        "   - ÂøÉÁêÜÂ±ÇÈù¢ÔºöË°•ÂÖÖÂ≠©Â≠êË°å‰∏∫ËÉåÂêéÁöÑÊΩúÂú®‰∏ªËßÇÊÑüÂèóÔºàÂ¶Ç‚ÄúÂèõÈÄÜË°å‰∏∫ËÉåÂêéÂÆûÂàôÊòØÊ∏¥ÊúõË¢´ÂÆ∂ÈïøÁêÜËß£ÔºåËÄåÈùûÂçïÁ∫ØÂØπÊäó‚ÄùÔºâÔºõ\n"
        "   - Âú∫ÊôØÁªÜËäÇÔºöË°•ÂÖÖÂêåÁ±ªÈóÆÈ¢òÁöÑÂÖ∏ÂûãË°®Áé∞ÔºàÂ¶Ç‚ÄúÂàù‰∏ÄÈò∂ÊÆµÂ≠©Â≠êÊ≠£Â§Ñ‰∫éÈùíÊò•ÊúüÊó©ÊúüÔºåÂèõÈÄÜË°å‰∏∫Â∏∏‰ΩìÁé∞‰∏∫ÊãíÁªùÊ≤üÈÄö„ÄÅÂàªÊÑèÁñèËøúÂÆ∂Èïø‚ÄùÔºâÔºõ\n"
        "   - ÂΩ±ÂìçÂª∂‰º∏ÔºöË°•ÂÖÖÈóÆÈ¢òÂèØËÉΩÂ∏¶Êù•ÁöÑÊΩúÂú®ÂΩ±ÂìçÔºàÂ¶Ç‚ÄúÈïøÊúüÊ∂àÊûÅÂéåÂ≠¶Ëã•Êú™Âπ≤È¢ÑÔºåÂèØËÉΩÂØºËá¥ÂêéÁª≠Â≠¶‰π†Âä®ÂäõÊåÅÁª≠‰∏ãÈôç‚ÄùÔºâÔºõ\n"
        "   - ËØ≠Ë®Ä‰ºòÂåñÔºöÂ∞ÜÂè£ËØ≠ÂåñË°®Ëø∞ËΩ¨‰∏∫‰∏ì‰∏ö„ÄÅÊµÅÁïÖÁöÑ‰π¶Èù¢ËØ≠ÔºåË°•ÂÖÖËøûÊé•ËØç/ÈÄªËæëËØç‰ΩøÂÜÖÂÆπÊõ¥ËøûË¥ØÔºõ\n"
        "3. „Äå‰∏ªË¶ÅÂõ∞Êâ∞„ÄçÔºöÂ≠óÊï∞‰∏çÂ∞ë‰∫é120Â≠óÔºåÂøÖÈ°ªÂåÖÂê´ÔºöÈóÆÈ¢òÊ†∏ÂøÉ+ÊåÅÁª≠Êó∂ÈïøÔºàÁ≤æÁ°ÆÂà∞Â§©/Âë®/ÊúàÔºâ+ ‰∏çÂêåÂú∫ÊôØ‰∏ãÁöÑÂÖ∑‰ΩìË°®Áé∞ + Â≠©Â≠êÁöÑ‰∏ªËßÇÊÑüÂèó + ÂÆûÈôÖÂΩ±ÂìçÔºõÂèØÊ∂¶Ëâ≤ËØ≠Ë®ÄÂπ∂Ê∑ªÂä†Ë°å‰∏∫ËÉåÂêéÁöÑÂøÉÁêÜÂä®Êú∫„ÄÅÂêåÁ±ªÈóÆÈ¢òÁöÑÂÖ∏ÂûãÁâπÂæÅÔºõ\n"
        "4. „ÄåËØ±Âõ†ÊàñÈáçË¶Å‰∫ã‰ª∂„ÄçÔºöÂ≠óÊï∞‰∏çÂ∞ë‰∫é100Â≠óÔºåÂøÖÈ°ªÂåÖÂê´Ôºö‰∫ã‰ª∂Êó∂Èó¥+ÂÖ∑‰ΩìÂú∫ÊôØ+ÂÆåÊï¥ËøáÁ®ã+Âç≥Êó∂ÂèçÂ∫î+ÂÖ≥ËÅîÈÄªËæëÔºõÂèØÊ∂¶Ëâ≤‰∫ã‰ª∂ÊèèËø∞ÁöÑËøûË¥ØÊÄßÔºåÂπ∂Ê∑ªÂä†‰∫ã‰ª∂ÂØπÂ≠©Â≠êÂøÉÁêÜÁä∂ÊÄÅÁöÑÊΩúÂú®ÂΩ±ÂìçÔºõ\n"
        "„ÄêËßíËâ≤‰∏éÊèêÂèñËåÉÂõ¥„Äë\n"
        "ÂØπËØùÊ†áÊ≥®„ÄêÂéüÂßãËßíËâ≤Ôºöxxx„ÄëÔºàÊ†áËØÜÂèØËÉΩÈîôËØØÔºâÔºåÂÖàÂà§Êñ≠ÁúüÂÆûËßíËâ≤Ôºö\n"
        "- Êù•ËÆøËÄÖ/ÂÆ∂Â±ûÔºö‰∏ªÂä®ÊèèËø∞Â≠©Â≠êÈóÆÈ¢ò„ÄÅËá™Ë∫´Âõ∞Êâ∞ÁöÑÂèÇ‰∏éÊñπÔºõ\n"
        "- Âí®ËØ¢Â∏àÔºöÂõûÂ∫î„ÄÅËØ¢ÈóÆÊÉÖÂÜµÁöÑÂèÇ‰∏éÊñπ„ÄÇ\n"
        "‰ªÖÊèêÂèñ„ÄêË¢´Âí®ËØ¢ÁöÑÂ≠©Â≠êÔºàÊ†∏ÂøÉÊù•ËÆøËÄÖÔºâ„ÄëÁöÑÂÖ≥ÈîÆ‰ø°ÊÅØÔºåÊåâ‰ª•‰∏ãÁª¥Â∫¶ÊÄªÁªìÔºàÊú™ÊèêÂèäÂàôÂ°´‚ÄúÊú™ÊèêÂèä‚ÄùÔºâÔºö\n"
        "1. Âü∫Êú¨ÊÉÖÂÜµÔºöÂπ¥ÈæÑÔºàÁ≤æÁ°ÆÂà∞Â≤ÅÔºâ„ÄÅÊÄßÂà´„ÄÅÂπ¥Á∫ß/Ë∫´‰ªΩ„ÄÅÊó•Â∏∏‰ΩúÊÅØ/ÂÖ¥Ë∂£Á≠âÂü∫Á°Ä‰ø°ÊÅØÔºõ\n"
        "2. ‰∏ªË¶ÅÂõ∞Êâ∞ÔºöÊåâ‰∏äËø∞Ê∂¶Ëâ≤/Ê∑ªÂä†Ë¶ÅÊ±ÇÔºåÂÆåÊï¥ÊèèËø∞Â≠©Â≠êÊ†∏ÂøÉÈóÆÈ¢òÂèäËÉåÊôØÔºõ\n"
        "3. ÁóáÁä∂Ë°®Áé∞ÔºöÊÉÖÁª™ÔºàÂ¶ÇÁÑ¶ËôëÁöÑÂÖ∑‰ΩìËß¶ÂèëÁÇπ/È¢ëÁéáÔºâ„ÄÅË∫Ø‰Ωì‰∏çÈÄÇÔºàÂÖ∑‰ΩìÈÉ®‰Ωç/Âèë‰ΩúÊó∂Èó¥Ôºâ„ÄÅÁù°Áú†ÔºàÂÖ•Áù°Êó∂Èïø/Â§úÈÜíÊ¨°Êï∞Ôºâ„ÄÅÂ≠¶‰π†/Á§æ‰∫§ÔºàÂÖ∑‰ΩìÂΩ±ÂìçÁ®ãÂ∫¶ÔºâÔºõ\n"
        "4. ËØ±Âõ†ÊàñÈáçË¶Å‰∫ã‰ª∂ÔºöÊåâ‰∏äËø∞Ê∂¶Ëâ≤/Ê∑ªÂä†Ë¶ÅÊ±ÇÔºåÂÆåÊï¥ËøòÂéüÂºïÂèëÈóÆÈ¢òÁöÑÂÖ≥ÈîÆ‰∫ã‰ª∂Ôºõ\n"
        "5. ÂÖ∂‰ªñ‰ø°ÊÅØÔºöÂÆ∂Â∫≠ÂÖ≥Á≥ªÔºàÂ¶ÇÂíåÁà∂ÊØçÁöÑÊ≤üÈÄöÈ¢ëÁéáÔºâ„ÄÅÂ≠¶Ê†°Ë°®Áé∞ÔºàÂ¶ÇÊúÄËøë‰∏ÄÊ¨°ËÄÉËØïÊéíÂêçÔºâ„ÄÅËøáÂæÄÁ±ª‰ººÊÉÖÂÜµÁ≠âÁªÜËäÇ„ÄÇ\n"
        "„ÄêÊ†áÂáÜÁ§∫‰æãÔºàÂøÖÈ°ª‰∏•Ê†ºÈÅµÂÆàÊ†ºÂºè+Ê∂¶Ëâ≤ÈÄªËæëÔºâ„Äë\n"
        "{\n"
        "  \"Âü∫Êú¨ÊÉÖÂÜµ\": \"17Â≤ÅÔºåÂ•≥ÔºåÈ´ò‰∏âÊñáÁßëÁè≠Â≠¶ÁîüÔºåÊó•Â∏∏ÊØèÂ§©Â≠¶‰π†Á∫¶10Â∞èÊó∂ÔºåÊó†ÊòéÊòæÂÖ¥Ë∂£Áà±Â•ΩÔºåÂë®Êú´Âü∫Êú¨Âú®ÂÆ∂Â§ç‰π†ÔºõÈ´ò‰∏âÈò∂ÊÆµÂ≠¶‰∏öÂéãÂäõÈô°Â¢ûÔºåÊòØËØ•Âπ¥ÈæÑÊÆµÂ≠¶ÁîüÁÑ¶ËôëÊÉÖÁª™È´òÂèëÁöÑÂÖ∏ÂûãÊó∂Êúü\",\n"
        "  \"‰∏ªË¶ÅÂõ∞Êâ∞\": \"ÈïøÊúüÂ≠òÂú®ËÄÉËØïÁÑ¶ËôëÈóÆÈ¢òÔºåËØ•ÊÉÖÂÜµ‰ªéÈ´ò‰∫å‰∏ãÂ≠¶ÊúüÔºàÁ∫¶8‰∏™ÊúàÂâçÔºâÂºÄÂßãÂá∫Áé∞Ôºå‰∏îËøë1‰∏™ÊúàÊÑàÂèë‰∏•ÈáçÔºõÂú®Ê†°ÊúüÈó¥Âè™Ë¶Å‰∏¥ËøëÊ®°ËÄÉÂ∞±‰ºöÂùêÁ´ã‰∏çÂÆâÔºåÊó†Ê≥ïÈõÜ‰∏≠Á≤æÂäõÂà∑È¢òÔºåÁîöËá≥‰ºöË∫≤Âú®Âç´ÁîüÈó¥Âì≠Ê≥£ÔºåÂú®ÂÆ∂Â§ç‰π†Êó∂ÁúãÂà∞ËØïÂç∑Â∞±‰ºöÊâãÊäñ„ÄÅÂøÉË∑≥Âä†ÈÄüÔºå‰∏ªËßÇ‰∏äËßâÂæó‚ÄúÂ¶ÇÊûúËÄÉ‰∏çÂ•ΩÂ∞±ÂØπ‰∏çËµ∑Áà∂ÊØç‚Äù‚Äî‚ÄîËøôÁßçË¥üÁΩ™ÊÑüÂÆûÂàôÊòØÈ´ò‰∏âÂ≠¶ÁîüÈù¢ÂØπÂçáÂ≠¶ÂéãÂäõÊó∂ÁöÑÂÖ∏ÂûãÂøÉÁêÜÂèçÂ∫îÔºõËØ•Áä∂ÊÄÅÂØºËá¥ÊúÄËøë‰∏âÊ¨°Ê®°ËÄÉÊï∞Â≠¶ÊàêÁª©‰ªé120ÂàÜÂ∑¶Âè≥‰∏ãÈôçÂà∞85ÂàÜÔºå‰∏î‰∏çÊÑøÂíåÂêåÂ≠¶ËÆ®ËÆ∫ËÄÉËØïÁõ∏ÂÖ≥ËØùÈ¢òÔºåÁ§æ‰∫§Ê¥ªÂä®Âá†‰πéÂÆåÂÖ®ÂÅúÊ≠¢ÔºåËøõ‰∏ÄÊ≠•Âä†Ââß‰∫ÜÂÖ∂Â≠§Áã¨ÊÑüÂíåÁÑ¶ËôëÊÑü\",\n"
        "  \"ÁóáÁä∂Ë°®Áé∞\": \"ÊØèÂë®Ëá≥Â∞ë3Ê¨°Âá∫Áé∞Ëé´ÂêçÁöÑÂøÉÊÖåÔºåÂÇçÊôöÊó∂ÊÆµÂ∞§‰∏∫ÊòéÊòæÔºàËØ•Êó∂ÊÆµÊòØÂ≠¶ÁîüÂ§çÁõòÂΩìÊó•Â≠¶‰π†ÊïàÊûú„ÄÅÂéãÂäõÊÑüÊúÄÂº∫ÁöÑÈò∂ÊÆµÔºâÔºõÂÖ•Áù°ÈúÄË¶Å1.5Â∞èÊó∂‰ª•‰∏äÔºåÊØèÊôöËá≥Â∞ëÂ§úÈÜí2Ê¨°ÔºåÊô®Ëµ∑ÊúâÂ§¥Êôï„ÄÅ‰πèÂäõÁöÑË∫Ø‰Ωì‰∏çÈÄÇÔºõ‰∏äËØæÊó†Ê≥ï‰∏ìÊ≥®Âê¨ËÆ≤ÔºåÁ¨îËÆ∞ËÆ∞ÂΩïÊ∑∑‰π±Ôºå‰Ωú‰∏öÂÆåÊàêÊïàÁéáËæÉ‰πãÂâç‰∏ãÈôç60%ÔºåÂΩ¢Êàê‚ÄúÊàêÁª©‰∏ãÊªë-ÁÑ¶ËôëÂä†Èáç‚ÄùÁöÑÊÅ∂ÊÄßÂæ™ÁéØ\",\n"
        "  \"ËØ±Âõ†ÊàñÈáçË¶Å‰∫ã‰ª∂\": \"Êú¨Ê¨°ÁÑ¶ËôëÂä†ÈáçÁöÑÁõ¥Êé•ËØ±Âõ†ÊòØ2‰∏™ÊúàÂâçÁöÑÂÖ®Â∏ÇÁªüËÄÉÔºåÂ≠©Â≠êÂéüÊú¨ÁõÆÊ†áÊòØÂπ¥Á∫ßÂâç50ÂêçÔºå‰ΩÜÊúÄÁªàÂè™ËÄÉ‰∫ÜÂπ¥Á∫ß120ÂêçÔºõËÄÉËØïÂΩìÂ§©Â≠©Â≠êÂõ†Á¥ßÂº†ÊºèÂÅö‰∫Ü‰∏§ÈÅìÂ§ßÈ¢òÔºåÂá∫ËÄÉÂú∫ÂêéË¢´ÊØç‰∫≤ÊåáË¥£‚Äú‰∏çÂ§üÂä™Âäõ‚ÄùÔºåÂõûÂÆ∂ÂêéÂíåÊØç‰∫≤ÂèëÁîüÊøÄÁÉà‰∫âÂêµÔºåÂΩìÊôöÂ§±Áú†Ëá≥ÂáåÊô®3ÁÇπÔºõËØ•‰∫ã‰ª∂‰∏ç‰ªÖËÆ©Â≠©Â≠ê‰∫ßÁîü‰∫ÜÂº∫ÁÉàÁöÑËá™ÊàëÂê¶ÂÆöÔºåËÆ§‰∏∫‚ÄúËá™Â∑±Ê∞∏ËøúËææ‰∏çÂà∞Áà∂ÊØçÁöÑË¶ÅÊ±Ç‚ÄùÔºåÊõ¥ËÆ©ÂÖ∂Â∞ÜËÄÉËØïÂ§±Ë¥•‰∏é‚ÄúËá™Ë∫´‰ª∑ÂÄº‚ÄùÁªëÂÆöÔºåËøõËÄåÂØºËá¥ÊØèÊ¨°ÁúãÂà∞ËØïÂç∑Â∞±Ëß¶ÂèëÁÑ¶ËôëÊÉÖÁª™ÔºåÂΩ¢ÊàêÊÅ∂ÊÄßÂæ™ÁéØ\",\n"
        "„ÄêÊúÄÁªàÊèêÈÜí„ÄëJSONÂøÖÈ°ªÂÆåÊï¥Èó≠ÂêàÔºàÂê´ÊúÄÂêéÁöÑÂºïÂè∑`\"`ÂíåÁªìÂ∞æÁ¨¶`}`ÔºâÔºåÂÜÖÂÆπÂèØÂÖÖÂàÜÊ∂¶Ëâ≤Âπ∂Ê∑ªÂä†ÈÄªËæëÁõ∏ÂÖ≥ÁªÜËäÇÔºå‰ΩÜÊâÄÊúâË°•ÂÖÖÂÜÖÂÆπÈúÄË¥¥ÂêàÂØπËØùÂ∑≤Êúâ‰ø°ÊÅØÔºå‰∏çÂæóÁºñÈÄ†Ê†∏ÂøÉ‰∫ãÂÆû„ÄÇ"
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": dialog_text},
    ]

    extraction = call_vllm(
        url=VLLM_URL,
        model=VLLM_MODEL,
        messages=messages,
        max_tokens=MAX_NEW_TOKENS
    )
    if extraction is not None:
        extraction = clean_extraction_result(extraction)
    
    return extraction
def process_single_sample(sample: Dict, source_file: str, out_f_path: str) -> Dict:
    item_id = sample["id"]
    messages = sample["messages"]
    result_obj = {
        "source_file": source_file,
        "id": item_id,
        "extraction": None,
        "is_valid_json": False,
        "error": None,
        "status": "failed"
    }

    try:
        dialog_text = build_dialog_text(messages)
        if not dialog_text.strip():
            result_obj["error"] = "Empty dialog, skipped"
            print_simple(f"üìå Sample ID: {item_id} | {result_obj['error']}")
            return result_obj

        extraction = call_chatmodeldp(dialog_text)
        result_obj["extraction"] = extraction

        print_simple("-" * 80)
        print_simple(f"üìå Processing sample | Source: {source_file} | ID: {item_id}")
        
        if extraction is None:
            result_obj["error"] = "VLLM call failed after retries"
            print_simple(f"‚ùå Extraction failed | Reason: {result_obj['error']}")
        else:
            try:
                json.loads(extraction)
                result_obj["is_valid_json"] = True
                result_obj["status"] = "success"
                is_valid = "‚úÖ Valid JSON"
            except json.JSONDecodeError:
                result_obj["is_valid_json"] = False
                result_obj["error"] = "Invalid JSON format"
                is_valid = "‚ùå Invalid JSON"
            
            preview_content = extraction[:PREVIEW_LENGTH] + "..." if len(extraction) > PREVIEW_LENGTH else extraction
            print_simple(f"üìù Result ({is_valid}) | Preview:\n{preview_content}")
        
        print_simple("-" * 80 + "\n")

        with WRITE_LOCK:
            with open(out_f_path, "a", encoding="utf-8") as out_f:
                out_f.write(json.dumps(result_obj, ensure_ascii=False) + "\n")
                out_f.flush()

    except Exception as e:
        error_msg = f"Sample processing error: {str(e)[:100]}"
        result_obj["error"] = error_msg
        result_obj["status"] = "error"
        result_obj["is_valid_json"] = False
        print_simple(f"‚ùå Sample ID: {item_id} | {error_msg}")

    return result_obj

def process_single_file_concurrent(path: str, out_f_path: str) -> Dict:
    print_simple(f"[info] Processing file: {path}")
    file_stats = {
        "file": path,
        "total_samples": 0,
        "valid_samples": 0,
        "success": 0,
        "failed": 0,
        "error": 0,
        "invalid_json_count": 0,
        "errors": []
    }

    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        error_msg = f"JSON parse failed: pos {e.pos} | {e.msg}"
        print_simple(f"‚ùå {error_msg}")
        file_stats["error"] += 1
        file_stats["errors"].append(error_msg)
        return file_stats
    except Exception as e:
        error_msg = f"File read failed: {str(e)[:50]}"
        print_simple(f"‚ùå {error_msg}")
        file_stats["error"] += 1
        file_stats["errors"].append(error_msg)
        return file_stats

    records = []
    if isinstance(data, list):
        records = data
    elif isinstance(data, dict) and "id" in data and "messages" in data:
        records = [data]
    elif isinstance(data, dict):
        for val in data.values():
            if isinstance(val, list):
                records.extend(val)
            elif isinstance(val, dict) and "id" in val and "messages" in val:
                records.append(val)

    valid_records = []
    for idx, item in enumerate(records):
        if (isinstance(item, dict) 
            and "id" in item 
            and "messages" in item 
            and isinstance(item["messages"], list)):
            valid_records.append(item)
        else:
            error_msg = f"Sample {idx} invalid (missing id/messages)"
            print_simple(f"‚ö†Ô∏è {error_msg}")
            file_stats["errors"].append(error_msg)

    file_stats["total_samples"] = len(records)
    file_stats["valid_samples"] = len(valid_records)

    if not valid_records:
        print_simple(f"[warn] No valid samples in file, skipped: {path}")
        return file_stats

    source_file_name = os.path.basename(path)
    futures = []
    with ThreadPoolExecutor(max_workers=MAX_CONCURRENCY) as executor:
        for sample in valid_records:
            future = executor.submit(
                process_single_sample,
                sample=sample,
                source_file=source_file_name,
                out_f_path=out_f_path
            )
            futures.append(future)

        for future in as_completed(futures):
            try:
                result = future.result()
                if result["status"] == "success":
                    file_stats["success"] += 1
                elif result["status"] == "failed":
                    file_stats["failed"] += 1
                    if not result["is_valid_json"] and result["extraction"] is not None:
                        file_stats["invalid_json_count"] += 1
                elif result["status"] == "error":
                    file_stats["error"] += 1
                
                if result["error"]:
                    file_stats["errors"].append(f"Sample {result['id']}: {result['error']}")
            except Exception as e:
                error_msg = f"Task execution error: {str(e)[:50]}"
                file_stats["error"] += 1
                file_stats["errors"].append(error_msg)

    print_simple(f"[info] File completed: {path} | Valid: {len(valid_records)} | Success: {file_stats['success']} | Failed: {file_stats['failed']} | Error: {file_stats['error']} | Invalid JSON: {file_stats['invalid_json_count']}")
    return file_stats
def main():
    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)
    
    with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
        f.write("")

    json_files = sorted(glob.glob(os.path.join(DATA_DIR, "*.json")))
    if not json_files:
        print_simple(f"[error] No JSON files found in {DATA_DIR}")
        return
    
    global_stats = {
        "total_files": len(json_files),
        "processed_files": 0,
        "total_samples": 0,
        "valid_samples": 0,
        "success": 0,
        "failed": 0,
        "error": 0,
        "invalid_json_count": 0
    }

    print_simple(f"[info] Found {len(json_files)} JSON files to process")
    print_simple(f"[info] Max concurrency: {MAX_CONCURRENCY}")
    print_simple(f"[info] Preview length: {PREVIEW_LENGTH} chars")
    print_simple(f"[info] Output: {OUTPUT_PATH}\n")

    for file_idx, path in enumerate(json_files, 1):
        print_simple(f"\n" + "="*100)
        print_simple(f"[info] Processing file {file_idx}/{len(json_files)}: {path}")
        file_stats = process_single_file_concurrent(path, OUTPUT_PATH)
        
        global_stats["processed_files"] += 1
        global_stats["total_samples"] += file_stats["total_samples"]
        global_stats["valid_samples"] += file_stats["valid_samples"]
        global_stats["success"] += file_stats["success"]
        global_stats["failed"] += file_stats["failed"]
        global_stats["error"] += file_stats["error"]
        global_stats["invalid_json_count"] += file_stats["invalid_json_count"]

    print_simple("\n" + "="*100)
    print_simple("‚úÖ All files processed! Final statistics:")
    print_simple(f"üìä Total files: {global_stats['total_files']} | Processed: {global_stats['processed_files']}")
    print_simple(f"üìä Total samples: {global_stats['total_samples']} | Valid: {global_stats['valid_samples']}")
    print_simple(f"üìä Success: {global_stats['success']} | Failed: {global_stats['failed']} | Error: {global_stats['error']}")
    print_simple(f"üìä Invalid JSON: {global_stats['invalid_json_count']}")
    print_simple(f"üìä Output file: {OUTPUT_PATH}")
    total_processed = global_stats["success"] + global_stats["failed"] + global_stats["error"]
    print_simple(f"üìä Total processed: {total_processed} (should equal valid: {global_stats['valid_samples']})")

if __name__ == "__main__":
    main()